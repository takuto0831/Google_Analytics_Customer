---
title: "Google Analytics Customer: EDA version1"
author: "kotsubo takuto"
output: 
    html_document:
      md_extensions: -ascii_identifiers
      toc: true
      toc_depth: 3
      code_folding: hide
---

# Setting{.tabset .tabset-fade .tabset-pills}

## knitr option

```{r reset, include=FALSE}
# 初期化
rm(list = ls())
```

```{r set up, message=FALSE}
# set directory
setwd("~/Desktop/Google_Analytics_Kaggle/") 
# max.print 
options(max.print="200", digits=5)
# Global options
library(knitr)
opts_chunk$set(echo=TRUE,
               cache = FALSE,
	             prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

## Library package

```{r package, message=FALSE}
library(tidyverse)
library(readr) # for csv
library(summarytools) # summary easily for EDA
library(GGally) # ggpairs
library(skimr) 
library(janitor)
library(jsonlite)
library(lubridate)
library(anytime)
```

## Load funciton

```{r}
source('~/Desktop/Google_Analytics_Kaggle/script/function.R') # for preprocessing
source('~/Desktop/Google_Analytics_Kaggle/script/makedummies.R') # for preprocessing
```

## Import csv

- Import raw data from `input/raw/{tarin|test}.csv`
- `device`, `geoNetwork`, `totals` and `trafficSource` are JSON style columns.

```{r cache=TRUE}
# read sample data
train_sample <- read_csv("~/Desktop/Google_Analytics_Kaggle/input/raw/train.csv",na = c("XNA","NA","","NaN","?"), n_max = 1000)
# extract columns class
col_vars_candidate <- train_sample %>% 
  map_chr(class)
col_vars <-  
      case_when(col_vars_candidate == "character" ~ "c",
                col_vars_candidate == "integer" ~ "i",
                col_vars_candidate == "numeric" ~ "d") %>% 
      purrr::set_names(names(col_vars_candidate)) %>% # set name by columns class
      as.list() %>% # list
      list_modify(date = "D", visitId = "c") %>% 
      flatten_chr() %>% # unlist
      str_c(collapse = "") # connect
# read raw data
train_raw <- read_csv("~/Desktop/Google_Analytics_Kaggle/input/raw/train.csv",
                      na = c("XNA","NA","","NaN","?"),
                      col_types = col_vars,
                      locale = readr::locale(date_format = "%Y%m%d"))
test_raw <- read_csv("~/Desktop/Google_Analytics_Kaggle/input/raw/test.csv",
                      na = c("XNA","NA","","NaN","?"),
                      col_types = col_vars,
                      locale = readr::locale(date_format = "%Y%m%d"))
# json columns
json_vars = c("device", "geoNetwork", "totals", "trafficSource")
# make a flatten data set
train_flat <- ReadJsonFile(train_raw, json_vars = json_vars)
test_flat <- ReadJsonFile(test_raw, json_vars = json_vars)
```

## Extract col names

- not execute

```{r eval=FALSE}
tmp <- (sapply(train_flat, class) %>% data.frame(train = .))
tmp <- (sapply(test_flat, class) %>% data.frame(test = .)) 

write.csv2(tmp,"~/Desktop/Google_Analytics_Kaggle/data/new_column_names.csv",row.names=TRUE)
# tmp %>% filter(str_detect(new,"id"))
```

# Explatory Data Analysis

- Apply glimpse, skimr and dfsummary to the all data
- Search target values
- Check three id values -> 2_EDA.Rmd
- Check time and date
- Confirm relationship with target variables -> 2_EDA.Rmd 

## Apply glimpse, skimr and dfsummary to the all data{.tabset .tabset-fade .tabset-pills}

### glimpse 

```{r cache=TRUE}
glimpse(train_flat)
glimpse(test_flat)
```

### skimr

```{r cache=TRUE}
skimr::skim_to_wide(train_flat) %>% kable()
skimr::skim_to_wide(test_flat) %>% kable()
```

### dfsummary

```{r cache=TRUE}
dfSummary(train_flat) %>% 
  view(method = "render")
dfSummary(test_flat) %>% 
  view(method = "render")
```

## Search target values

- target: `transactionRevenue`
- `campaignCode` is nothing in test data

```{r}
tmp <- train_flat %>% 
  colnames() %>%
  data.frame(col = .,train = 1) %>% 
  full_join(test_flat %>% 
              colnames() %>% 
              data.frame(col = ., test = 1),
            by = "col")
```

```{r}
train_flat %>% 
  mutate(transactionRevenue = 
           transactionRevenue %>% 
           as.numeric()
           ) %>% 
  summarise(a = min(transactionRevenue, na.rm = TRUE) / 10^6,
            b = max(transactionRevenue, na.rm = TRUE) / 10^6,
            c = mean(transactionRevenue, na.rm = TRUE) / 10^6)
```

- 80 / 20 rule -> result: 72%

```{r}
train_flat %>% 
  select(transactionRevenue) %>% 
  mutate(transactionRevenue = transactionRevenue %>% as.numeric()) %>% 
  na.omit() %>% 
  arrange(desc(transactionRevenue))-> tmp 

(tmp[1:2300,1] %>% sum()) / (tmp %>% sum)
```

## Check three id values

- `fullVisitorId`
- `sessionId`
- `visitId`

- uniqueな値を確認する. 

```{r}
# train
train_flat %>% distinct(fullVisitorId) %>% NROW
train_flat %>% distinct(sessionId) %>% NROW
train_flat %>% distinct(visitId) %>% NROW
# test
test_flat %>% distinct(fullVisitorId) %>% NROW
test_flat %>% distinct(sessionId) %>% NROW
test_flat %>% distinct(visitId) %>% NROW
```

- 2つのIDを組み合わせると, `sessionId` と同じ結果になる
- `visitId` 必要なのか?

```{r}
train_flat %>% distinct(fullVisitorId, visitId) %>% NROW
test_flat %>% distinct(fullVisitorId, visitId) %>% NROW
```

- `sessionId` は `fullVisitorId`と`visitId`により形成されていることを確認する

```{r}
train_flat %>% 
  unite(tm, fullVisitorId, visitId,sep="_") %>% 
  filter(tm != sessionId) %>% 
  NROW
test_flat %>% 
  unite(tm, fullVisitorId, visitId,sep="_") %>% 
  filter(tm != sessionId) %>% 
  NROW
```

- train, testに同一のuserは出現していないか
- user id: 全1331409種 (unique value: 1323730)
- 同一のuserが存在する. 

```{r}
train_flat %>% 
  distinct(fullVisitorId) %>% 
  rbind(test_flat %>% distinct(fullVisitorId)) -> tmp
tmp %>% distinct(fullVisitorId) %>% NROW
```

- trainの購入履歴あり + test: 627,238 (unique: 626702)
- 536人は購入かつ再度訪問している.

```{r}
train_flat %>% 
  filter(!is.na(transactionRevenue)) %>% 
  distinct(fullVisitorId) %>% 
  rbind(test_flat %>% distinct(fullVisitorId)) -> tmp
tmp %>% distinct(fullVisitorId) %>% NROW
```

- 同一の`sessionId`が複数回出現 -> 同一の会計履歴が複数存在する -> 購入の場合しかありえない??
- idの解釈が間違っている -> 2_EDA.Rmd

```{r eval=FALSE}
train_flat %>% 
  mutate(transactionRevenue = transactionRevenue %>% as.numeric()) %>% 
  group_by(sessionId) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  filter(count >= 2) -> tmp
tmp %>% 
  inner_join(train_flat,by="sessionId") -> tmp1
```

## Check time and date

- 観測期間の確認
- train: 1年間, test: 8ヶ月

```{r}
train_flat %>% 
  summarise(from = min(date), to = max(date))
test_flat %>% 
  summarise(from = min(date), to = max(date))
```

- time zone is "US/Pacific"

```{r}
train_flat %>% 
  mutate(visitStartTime = as.POSIXct(visitStartTime, origin='1970-01-01', tz = "US/Pacific") %>% date()) %>% 
  select(date, visitStartTime) %>% 
  mutate(check = date - visitStartTime) %>% 
  summarise(max(check), min(check))
test_flat %>% 
  mutate(visitStartTime = as.POSIXct(visitStartTime, origin='1970-01-01', tz = "US/Pacific") %>% date()) %>% 
  select(date, visitStartTime) %>% 
  mutate(check = date - visitStartTime) %>% 
  summarise(max(check), min(check))
```
